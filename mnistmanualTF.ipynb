{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnistmanualTF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedQaraad/DeepleerningTF/blob/master/mnistmanualTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJW5-A-WeaIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#هنا نقوم بقراء الداتا سيت اللي اسمها mnist \n",
        "#والموجودة في ملف اسمه data\n",
        "#نقوم بقراءة الداتا سيت كاملة \n",
        "#طبعا اي داتا سيت تقسم الى ثلاثة اقسام  train  - validation  - test \n",
        "# هذه الداتا سيت مقسمة جاهزة \n",
        "#الداتا سيت هذه عبارة عن صور للكتابة بخط اليد للراقام من 0 - 9\n",
        "#بمعنى ان لدينا  10 كلاس ليبل في ال output layer \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./data/\")\n",
        "#اصبخت الداتا سيت مخزنة في متغير mnist "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ndS0Fine3fX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "57b8a613-06af-432e-b18d-f51265b066b1"
      },
      "source": [
        "#لمعرفة عدد الصور المخصصة لكي يقوم النموذج بالتدرب عليها في الداتا سيت \n",
        "print('number of training data   {}'.format (mnist.train.num_examples))\n",
        "\n",
        "#لمعرفة عدد الصور المخصصة لكي يقوم النموذج بعملية ضبط الباراميترات عليها في الداتا سيت \n",
        "print('number of validation data   {}'.format (mnist.validation.num_examples))\n",
        "\n",
        "#لمعرفة عدد الصور المخصصة لفحص النموذج ما اذا كان يعمل بشكل سليم او لا  \n",
        "print('number of testing  data   {}'.format (mnist.test.num_examples))\n",
        "\n",
        "#حجم الداتا ست كاملة \n",
        "print('total dataset size  {} '.format(mnist.train.num_examples + mnist.test.num_examples + mnist.validation.num_examples))\n",
        "\n",
        "\n",
        "print(mnist.train.labels.shape)\n",
        "mnist.train.labels[0]\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training data   55000\n",
            "number of validation data   5000\n",
            "number of testing  data   10000\n",
            "total dataset size  70000 \n",
            "(55000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a03tc4cKg417",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n_epochs = 400\n",
        "batch_size = 50\n",
        "#هذه المتغيرات بتحدد حاجتين الاولى عدد المرات التي بيشتغل عليها النموذج على الداتا ست بتاع التدريب  وهي اربعمئة مرة \n",
        "#المتغير الاخر بما ان الداتا سيت الخاصة بالتدريب كبيرة فيتم اخذ اربعين صورة والتعلم عليها ومن ثم اربعين اخرى يعني ما ياخذ كل الداتا مرة واحدة "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEzhXIBNh0--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5449d8c4-397c-4da6-b4a7-66ee72c5ed0f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from datetime import datetime\n",
        "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir='./graphs'\n",
        "logdir=\"{}/run-{}/\".format(root_logdir, now)\n",
        "file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
        "logdir"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./graphs/run-20190610223807/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuw_-gKtis8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "deff5f05-3c74-4b1c-b81c-65cf00834fb0"
      },
      "source": [
        "# هنا نقوم ببناء الشبكة العصبية اي النموذج \n",
        "n_inputs = 28*28 # MNIST  input layer \n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "\n",
        "from tensorflow.contrib.layers import fully_connected\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
        "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
        "    logits = fully_connected(hidden2, n_outputs, scope=\"outputs\",activation_fn=None)\n",
        "    \n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "    \n",
        "learning_rate = 0.01\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "    \n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifEH_N6FjRRq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e50740c-6a71-48ee-9a6a-440abc650fa8"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(5): #\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
        "    print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 Train accuracy: 0.94 Test accuracy: 0.9434\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}